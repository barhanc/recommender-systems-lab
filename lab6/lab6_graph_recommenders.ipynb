{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorium 6 - rekomendacje grafowe\n",
    "\n",
    "## Przygotowanie\n",
    "\n",
    " * pobierz i wypakuj dataset `movies_graph.zip`\n",
    "   * dane źródłowe: https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/data\n",
    "   * więcej o przekształceniach i filtrowaniu możesz poczytać w notebooku `movies_graph_data_preparation.ipynb`\n",
    " * [opcjonalnie] Utwórz wirtualne środowisko\n",
    " `python3 -m venv ./recsyslab6`\n",
    " * zainstaluj potrzebne biblioteki:\n",
    " `pip install pykeen torch tqdm seaborn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 1. - przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import csv\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from random import shuffle\n",
    "\n",
    "import tqdm as notebook_tqdm\n",
    "import torch\n",
    "from pykeen.models import ERModel, TransE\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.predict import predict_target\n",
    "from pykeen.triples import TriplesFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'movies_graph'\n",
    "TRAIN_DATA_RATIO = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataclasses\n",
    "\n",
    "class Movie:\n",
    "    def __init__(self,\n",
    "                 movie_id: str,\n",
    "                 title: str,\n",
    "                 genres: List[str], \n",
    "                 production_countries: List[str], \n",
    "                 collection_name: str,\n",
    "                 release_year: str):\n",
    "        self.movie_id = movie_id\n",
    "        self.title = title\n",
    "        self.genres = genres\n",
    "        self.production_countries = production_countries\n",
    "        self.collection_name = collection_name\n",
    "        self.release_year = release_year\n",
    "    \n",
    "    def add_cast(self,\n",
    "                 actors: List[str],\n",
    "                 directors: List[str],\n",
    "                 screenwriters: List[str],\n",
    "                 music_composers: List[str]):\n",
    "        self.actors = actors\n",
    "        self.directors = directors\n",
    "        self.screenwriters = screenwriters\n",
    "        self.music_composers = music_composers\n",
    "    \n",
    "    def basic_info(self):\n",
    "        return {\n",
    "            'movie_id': self.movie_id,\n",
    "            'title': self.title,\n",
    "            'genres': self.genres,\n",
    "            'production_countries': self.production_countries\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(vars(self))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, user_id: str, movie_id: str, rating: str):\n",
    "        self.user_id = user_id\n",
    "        self.movie_id = movie_id\n",
    "        self.rating = float(rating)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(vars(self))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytujemy oceny filmow\n",
    "with open('movies_graph/reviews.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    ratings = []\n",
    "    for entry in list(reader):\n",
    "        user_id, movie_id, rating = entry\n",
    "        ratings.append(Review(f'u_{user_id}', f'm_{movie_id}', rating))\n",
    "\n",
    "# podzial na zbior treningowy i testowy\n",
    "shuffle(ratings)\n",
    "train_ratings = ratings[:int(len(ratings)*TRAIN_DATA_RATIO)]\n",
    "test_ratings = ratings[len(train_ratings):]\n",
    "train_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytujemy metadane filmow\n",
    "def parse_movie_metadata(entry: List[str]):\n",
    "    movie_id, title, genres, production_countries, collection_name, release_year = entry\n",
    "    return Movie(f'm_{movie_id}', title, literal_eval(genres), literal_eval(production_countries), collection_name, release_year)\n",
    "\n",
    "def add_cast_to_movie(movie: Movie, entry: List[str]):\n",
    "    _movie_id, actors, directors, screenwriters, music_composers = entry\n",
    "    movie.add_cast(literal_eval(actors), literal_eval(directors), literal_eval(screenwriters), literal_eval(music_composers))\n",
    "\n",
    "with open('movies_graph/metadata.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    movies = {f'm_{entry[0]}': parse_movie_metadata(entry) for entry in reader}\n",
    "\n",
    "with open('movies_graph/credits.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    for entry in reader:\n",
    "        movie_id = f'm_{entry[0]}'\n",
    "        add_cast_to_movie(movies[movie_id], entry)\n",
    "\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 2. - zbudowanie zbioru relacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generujemy dane dla modelu w formacie (head, relation, tail)\n",
    "# na start mozesz uzyc malego podzbioru relacji, np. tylko 'positive_rating'\n",
    "\n",
    "all_relation_types = [\n",
    "    'positive_rating',\n",
    "    'neutral_rating',\n",
    "    'negative_rating',\n",
    "    'genre',\n",
    "    'production_country',\n",
    "    'in_collection',\n",
    "    'release_year',\n",
    "    'actor_in',\n",
    "    'director_of',\n",
    "    'screenwriter_of',\n",
    "    'composer_of'\n",
    "]\n",
    "basic_relation_types = [\n",
    "    'positive_rating',\n",
    "    'negative_rating'\n",
    "]\n",
    "\n",
    "def generate_triples(reviews: List[Review], movies: Dict[str, Movie], relation_types: List[str]) -> List[Tuple[str, str, str]]:\n",
    "    # przetlumacz dane o filmach i recenzjach do formy trojek (head, relation, tail)\n",
    "    # np. (user_id, 'positive_rating', movie_id)\n",
    "    # zwroc liste trzyelementowych krotek\n",
    "    raise NotImplementedError()\n",
    "\n",
    "triples = generate_triples(ratings, movies, basic_relation_types)\n",
    "tf = TriplesFactory.from_labeled_triples(np.array(triples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 3. - trening modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(triples: List[Tuple[str, str, str]], tf: TriplesFactory):\n",
    "    # tworzymy obiekt pomocniczy do reprezentacji zbioru danych\n",
    "    training, testing, validation = tf.split([.8, .1, .1])\n",
    "\n",
    "    # fix dla niektorych makow\n",
    "    # mps_device = torch.device(\"mps\")\n",
    "\n",
    "    # zasadnicza czesc treningu\n",
    "    pipeline_result = pipeline(\n",
    "        # device=mps_device, \n",
    "        training=training,\n",
    "        testing=testing,\n",
    "        validation=validation,\n",
    "        model=TransE, # to najszybszy i najprostszy, ale i najslabszy model\n",
    "        epochs=10 # to tylko przykladowa wartosc, na podstawie loss plot ocenimy, czy wystarczy\n",
    "    )\n",
    "    return pipeline_result\n",
    "\n",
    "pipeline_result = train_model(triples, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykres loss function\n",
    "pipeline_result.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 4. - rekomendacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcje pomocnicze\n",
    "def print_movies(movie_ids: List[str], movies: Dict[str, Movie], print_missing=True):\n",
    "    for m_id in movie_ids:\n",
    "        if m_id in movies:\n",
    "            print(movies[m_id].basic_info())\n",
    "        elif print_missing:\n",
    "            print(f'movie_id: {m_id}')\n",
    "\n",
    "def describe_user(user_id: str, reviews: List[Review], movies: Dict[str, Movie]):\n",
    "    positive_ratings = [x.movie_id for x in reviews if x.user_id == user_id and x.rating >= 4.0]\n",
    "    negative_ratings = [x.movie_id for x in reviews if x.user_id == user_id and x.rating <= 2.0]\n",
    "    neutral_ratings = [x.movie_id for x in reviews if x.user_id == user_id and x.rating > 2.0 and x.rating < 4.0]\n",
    "    \n",
    "    print(f'user_id: {user_id}')\n",
    "    print('Positive ratings:')\n",
    "    print_movies(positive_ratings, movies, print_missing=False)\n",
    "    print('Neutral ratings:')\n",
    "    print_movies(neutral_ratings, movies, print_missing=False)\n",
    "    print('Negative ratings:')\n",
    "    print_movies(negative_ratings, movies, print_missing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id: str, model: ERModel, triples_factory: TriplesFactory, k: int) -> List[str]:\n",
    "    relation = 'positive_rating'\n",
    "    prediction = predict_target(model, head=user_id, relation=relation, triples_factory=triples_factory)\n",
    "    # wygeneruj rekomendacje na podstawie predykcji\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id = 'u_547' # uzytkownik z bardzo duza historia\n",
    "user_id = 'u_244'\n",
    "describe_user(user_id, ratings, movies)\n",
    "recommendation = recommend(user_id, pipeline_result.model, tf, 20)\n",
    "print('Recommendation:')\n",
    "print_recommendation(recommendation, movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 5. - metryki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HitRatio@k - iterujemy po testowym zbiorze ocen, odsiewamy tylko oceny pozytywne,\n",
    "# generujemy rekomendacje dlugosci k dla uzytkownika i sprawdzamy, czy oceniony film znalazl sie w rekomendacji\n",
    "# zwracamy stosunek liczby trafien do liczby wszystkich prob\n",
    "\n",
    "# wersja nieco bardziej zaawansowana - zamiast rekomendacji wyciagamy z modelu predykcje konkretnej relacji\n",
    "# i liczymy skutecznosc w przewidywaniu, czy ocena byla pozytywna, negatywna czy neutralna\n",
    "\n",
    "def hit_ratio(test_ratings: List[Review], model: ERModel, tf: TriplesFactory, k: int) -> float:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "hit_ratio(test_ratings, pipeline_result.model, tf, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AvgPosition@k - iterujemy po testowym zbiorze ocen, odsiewamy tylko oceny pozytywne,\n",
    "# generujemy rekomendacje dlugosci k dla uzytkownika i sprawdzamy, czy oceniony film znalazl sie w rekomendacji\n",
    "# jesli tak, zapisujemy pozycje, na ktorej zarekomendowano film\n",
    "# zwracamy srednia pozycje, na ktorych wystepowaly filmy\n",
    "\n",
    "def avg_position(test_ratings: List[Review], model: ERModel, tf: TriplesFactory, k: int) -> float:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "avg_position(test_ratings, pipeline_result.model, tf, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 5. - porównanie modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wytrenowaliśmy podstawowy model, umiemy wygenerować rekomendacje i ocenić jakość modelu. Teraz przeanalizujemy, jakie zmiany mogą pozytywnie wpłynąć na jakość rekomendacji.\n",
    "\n",
    "Porównaj bazowy model (np. TransH wytrenowany tylko na relacjach `positive_rating` i `negative_rating`) z dwoma innymi podejściami. Wybierz dwie spośród poniszych modyfikacji lub zaproponuj własną:\n",
    "1. Zmiana modelu - zamiast TransH możesz użyć np. TransR albo RESCAL\n",
    "2. Dodanie większej liczby typów relacji - możesz dodać oceny neutralne, metadane filmu, informacje o obsadzie. Nawet jeśli jakaś relacja nie jest wykorzystywana w procesie rekomendacji, może poprawić jakość wytrenowanego modelu. Zwróć uwagę, by jako rekoemndację zwracać wyłącznie identyfikatory filmów, nie innych wierzchołków.\n",
    "3. Zmiana sposobu rekomendacji - obecny tryb opiera się na przewidywaniu relacji `positive_rating`. Możesz poprawić ten proces przez np. odsiewanie tych kandydatów, którzy występują także w predykcji relacji `negative_rating` czy filtrowanie kandydatów po metadanych (np. gatunku).\n",
    "\n",
    "Porównanie trzech modeli oprzyj na dwóch zdefiniowanych w Części 4. metrykach dla wybranej wartości `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
